{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Fix image namings\n",
    "# TODO: FIx channel correspondance\n",
    "# TODO: Remove iteration over two images and loading images from disk\n",
    "# TODO: rename channels to object type\n",
    "# run on 13254, 14457, 13359\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import omero_toolbox as omero\n",
    "from getpass import getpass\n",
    "import subprocess\n",
    "from skimage.filters import threshold_otsu, apply_hysteresis_threshold\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, cube, disk\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level='INFO')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define variables\n",
    "HOST = 'omero.mri.cnrs.fr'\n",
    "PORT = 4064\n",
    "TEMP_DIR = '/run/media/julio/DATA/Maria/temp'\n",
    "ILASTIK_PATH = '/home/julio/Apps/ilastik-1.3.2post1-Linux/run_ilastik.sh'\n",
    "PROJECT_PATH = '/run/media/julio/DATA/Maria/projects/HippocampalGliosis_v1.ilp'\n",
    "# PROJECT_PATH = '/run/media/julio/DATA/Maria/projects/Neuronal_death_v1.ilp'\n",
    "\n",
    "# Probability image is referring to channels in aip_image as follows:\n",
    "# (object_ch, prb_ch)\n",
    "object_ch_match = [(0, 0),\n",
    "                   (1, 1),\n",
    "                   (2, 2),\n",
    "                   ]\n",
    "# object_ch_match = [(0, 0),\n",
    "#                    (1, 1),\n",
    "#                    ]\n",
    "ch_bg_match = [(0, 3),\n",
    "               (1, 3),\n",
    "               (2, 3)]\n",
    "# ch_bg_match = [(0, 2),\n",
    "#                (1, 2),\n",
    "#                ]\n",
    "\n",
    "ch_names = ['Microglie', 'Astrocyte', 'Neurone']\n",
    "# ch_names = ['Nuclei', 'Neurons_F1B']\n",
    "\n",
    "segmentation_thr = [150,\n",
    "                    150,\n",
    "                    180,\n",
    "                    200]\n",
    "# segmentation_thr = [150,\n",
    "#                     150,\n",
    "#                     200]\n",
    "upper_correction_factors = [1,\n",
    "                            1,\n",
    "                            1,\n",
    "                            1]\n",
    "# upper_correction_factors = [1,\n",
    "#                             1,\n",
    "#                             1]\n",
    "lower_correction_factors = [0.8,\n",
    "                            0.8,\n",
    "                            0.8,\n",
    "                            1]\n",
    "# lower_correction_factors = [0.8,\n",
    "#                             0.8,\n",
    "#                             1]\n",
    "\n",
    "\n",
    "def run_ilastik(ilastik_path, input_path, model_path):\n",
    "\n",
    "    cmd = [ilastik_path,\n",
    "           '--headless',\n",
    "           f'--project={model_path}',\n",
    "           '--export_source=Probabilities',\n",
    "           '--output_format=numpy',\n",
    "           # '--output_filename_format={dataset_dir}/{nickname}_Probabilities.npy',\n",
    "           '--export_dtype=uint8',\n",
    "           # '--output_axis_order=zctyx',\n",
    "           input_path]\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, stdout=subprocess.PIPE).stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Input command: {cmd}')\n",
    "        print()\n",
    "        print(f'Error: {e.output}')\n",
    "        print()\n",
    "        print(f'Command: {e.cmd}')\n",
    "        print()\n",
    "\n",
    "\n",
    "def segment_channel(channel, threshold=None, min_distance=2, remove_border=False, low_corr_factor=1, high_corr_factor=1):\n",
    "    \"\"\"Segment a channel (3D numpy array)\n",
    "    \"\"\"\n",
    "    if threshold is None:\n",
    "        threshold = threshold_otsu(channel)\n",
    "\n",
    "    thresholded = apply_hysteresis_threshold(channel,\n",
    "                                             low=threshold * low_corr_factor,\n",
    "                                             high=threshold * high_corr_factor\n",
    "                                             )\n",
    "\n",
    "    thresholded = closing(thresholded, disk(min_distance))\n",
    "    if remove_border:\n",
    "        thresholded = clear_border(thresholded)\n",
    "    return label(thresholded)\n",
    "\n",
    "\n",
    "def segment_image(image,\n",
    "                  thresholds=None,\n",
    "                  low_corr_factors=None,\n",
    "                  high_corr_factors=None):\n",
    "    \"\"\"Segment an image and return a labels object.\n",
    "    Image must be provided as cyx numpy array\n",
    "    \"\"\"\n",
    "    if len(image.shape) < 3:\n",
    "        image = np.expand_dims(image, 0)\n",
    "\n",
    "    if low_corr_factors is None:\n",
    "        low_corr_factors = [.95] * image.shape[0]\n",
    "    if high_corr_factors is None:\n",
    "        high_corr_factors = [1.05] * image.shape[0]\n",
    "\n",
    "    if len(high_corr_factors) != image.shape[0] or len(low_corr_factors) != image.shape[0]:\n",
    "        raise Exception('The number of correction factors does not match the number of channels.')\n",
    "\n",
    "    # We create an empty array to store the output\n",
    "    labels_image = np.zeros(image.shape, dtype=np.uint16)\n",
    "    for c in range(image.shape[0]):\n",
    "        threshold = thresholds[c] if thresholds is not None else None\n",
    "        labels_image[c, ...] = segment_channel(image[c, ...],\n",
    "                                               threshold=threshold,\n",
    "                                               low_corr_factor=low_corr_factors[c],\n",
    "                                               high_corr_factor=high_corr_factors[c])\n",
    "    return labels_image\n",
    "\n",
    "\n",
    "def compute_channel_spots_properties(channel, label_channel):\n",
    "    \"\"\"Analyzes and extracts the properties of a single channel\"\"\"\n",
    "\n",
    "    ch_properties = []\n",
    "    logger.info(f'label_channel dims: {label_channel.shape}')\n",
    "    logger.info(f'channel dims: {channel.shape}')\n",
    "    regions = regionprops(label_channel, channel)\n",
    "\n",
    "    for region in regions:\n",
    "        ch_properties.append({'label': region.label,\n",
    "                              'area': region.area,\n",
    "                              'centroid_x': region.centroid[1],\n",
    "                              'centroid_y': region.centroid[0],\n",
    "                              'eccentricity': region.eccentricity,\n",
    "                              'perimeter': region.perimeter,\n",
    "                              'max_intensity': region.max_intensity,\n",
    "                              'mean_intensity': region.mean_intensity,\n",
    "                              'min_intensity': region.min_intensity,\n",
    "                              'integrated_intensity': region.mean_intensity * region.area\n",
    "                              })\n",
    "\n",
    "    return ch_properties\n",
    "\n",
    "\n",
    "def compute_spots_properties(image, labels):\n",
    "    \"\"\"Computes a number of properties for the PSF-like spots found on an image provided they are segmented\"\"\"\n",
    "    # TODO: Verify dimensions of image and labels are the same\n",
    "    properties = []\n",
    "\n",
    "    for c in range(image.shape[0]):  # TODO: Deal with Time here\n",
    "        pr = compute_channel_spots_properties(channel=image[c, :, :],\n",
    "                                              label_channel=labels[c, :, :],\n",
    "                                              )\n",
    "        properties.append(pr)\n",
    "\n",
    "    return properties\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # Open the connection to OMERO\n",
    "        conn = omero.open_connection(username=input(\"Username: \"),\n",
    "                                     password=getpass(\"OMERO Password: \", None),\n",
    "                                     host=str(input('server (omero.mri.cnrs.fr): ') or HOST),\n",
    "                                     port=int(input('port (4064): ') or PORT),\n",
    "                                     group=input(\"Group: \"))\n",
    "\n",
    "        # get tagged images in dataset\n",
    "        dataset_id = int(input('Dataset ID: '))\n",
    "        dataset = omero.get_dataset(conn, dataset_id)\n",
    "        project = dataset.getParent()\n",
    "\n",
    "        new_dataset_name = f'{dataset.getName()}_ilastik_output'\n",
    "        new_dataset_description = f'Source Dataset ID: {dataset.getId()}'\n",
    "        new_dataset = omero.create_dataset(conn,\n",
    "                                           name=new_dataset_name,\n",
    "                                           description=new_dataset_description,\n",
    "                                           parent_project=project)\n",
    "\n",
    "        images = dataset.listChildren()\n",
    "\n",
    "        images_names_ids = {i.getName(): i.getId() for i in images}\n",
    "        image_root_names = list(set([n[:-4] for n in images_names_ids.keys()]))\n",
    "\n",
    "        table_col_names = ['image_id',\n",
    "                           'image_name',\n",
    "                           'mouse_nr',\n",
    "                           'replica_nr',\n",
    "                           'genotype',\n",
    "                           'treatment',\n",
    "                           'roi_area']\n",
    "\n",
    "        for ch_name in ch_names:\n",
    "            table_col_names.extend([f'roi_intensity_{ch_name}',\n",
    "                                    f'object_count_{ch_name}',\n",
    "                                    f'mean_area_{ch_name}',\n",
    "                                    f'median_area_{ch_name}',\n",
    "                                    f'sum_area_{ch_name}',\n",
    "                                    f'sum_intensity_{ch_name}',\n",
    "                                    f'mean_intensity_{ch_name}',\n",
    "                                    f'sum_area_bg_{ch_name}',\n",
    "                                    f'sum_intensity_bg_{ch_name}',\n",
    "                                    f'mean_intensity_bg_{ch_name}'\n",
    "                                    ])\n",
    "        table_col_values = [[] for _ in range(len(table_col_names))]\n",
    "\n",
    "        for counter, image_root_name in enumerate(image_root_names):\n",
    "            logger.info(f'Analyzing image {image_root_name}')\n",
    "\n",
    "            mip_image = conn.getObject('Image', images_names_ids[f'{image_root_name}_MIP'])\n",
    "            mip_data = omero.get_intensities(mip_image)\n",
    "            aip_image = conn.getObject('Image', images_names_ids[f'{image_root_name}_AIP'])\n",
    "            aip_data = omero.get_intensities(aip_image)\n",
    "\n",
    "            # Filling data table\n",
    "            name_md = image_root_name.strip()\n",
    "            name_md = name_md.replace(' ', '_').split('_')\n",
    "\n",
    "            table_col_values[0].append(aip_image)  # 'image_id'\n",
    "            table_col_values[1].append(image_root_name)  # 'image_name'\n",
    "            table_col_values[2].append(name_md[0])  # 'mouse_nr'\n",
    "            table_col_values[3].append(name_md[1])  # 'replica_nr'\n",
    "            table_col_values[4].append(name_md[2])  # 'genotype'\n",
    "            table_col_values[5].append(name_md[3])  # 'treatment'\n",
    "\n",
    "            # Some basic measurements\n",
    "            roi_area = np.count_nonzero(aip_data[0, 0, 0, ...])\n",
    "            table_col_values[6].append(roi_area)  # 'roi_area'\n",
    "\n",
    "            # We were downloading the images without the z dimension so we have to remove it here\n",
    "            # mip_data = mip_data.squeeze(axis=0)\n",
    "\n",
    "            temp_file = f'{TEMP_DIR}/{mip_image.getName()}.npy'\n",
    "            np.save(temp_file, mip_data)\n",
    "\n",
    "            run_ilastik(ILASTIK_PATH, temp_file, PROJECT_PATH)\n",
    "\n",
    "            output_file = f'{TEMP_DIR}/{mip_image.getName()}_Probabilities.npy'\n",
    "            prob_data = np.load(output_file)\n",
    "\n",
    "            # Save the output back to OMERO\n",
    "            omero.create_image_from_numpy_array(connection=conn,\n",
    "                                                data=prob_data,\n",
    "                                                image_name=f'{mip_image.getName()}_PROB',\n",
    "                                                image_description=f'Source Image ID:{mip_image.getId()}',\n",
    "                                                dataset=new_dataset,\n",
    "                                                channel_labels=ch_names + ['background'],\n",
    "                                                force_whole_planes=False\n",
    "                                                )\n",
    "\n",
    "            prob_data = prob_data.squeeze()\n",
    "            aip_data = aip_data.squeeze()\n",
    "\n",
    "            for object_ch, bg_ch in zip(object_ch_match, ch_bg_match):\n",
    "                # Keep connection alive\n",
    "                conn.keepAlive()\n",
    "                # Calculate object properties on the objects\n",
    "                object_labels = segment_channel(channel=prob_data[object_ch[1]], threshold=segmentation_thr[object_ch[1]])\n",
    "                object_properties = compute_channel_spots_properties(channel=aip_data[object_ch[0]], label_channel=object_labels)\n",
    "                object_df = pd.DataFrame(object_properties)\n",
    "\n",
    "                # Calculate properties of the background\n",
    "                bg_labels = segment_channel(channel=prob_data[bg_ch[1]], threshold=segmentation_thr[bg_ch[1]])\n",
    "                bg_properties = compute_channel_spots_properties(channel=aip_data[bg_ch[0]], label_channel=bg_labels)\n",
    "                bg_df = pd.DataFrame(bg_properties)\n",
    "\n",
    "                # Save dataframes as csv attachments to the images\n",
    "                object_df.to_csv(f'{TEMP_DIR}/ch{object_ch[0]}_object_df.csv')\n",
    "                object_csv_ann = omero.create_annotation_file_local(\n",
    "                    connection=conn,\n",
    "                    file_path=f'{TEMP_DIR}/ch{object_ch[0]}_object_df.csv',\n",
    "                    description=f'Data corresponding to the objects on channel {object_ch[0]}')\n",
    "                omero.link_annotation(aip_image, object_csv_ann)\n",
    "\n",
    "                bg_df.to_csv(f'{TEMP_DIR}/ch{bg_ch[0]}_bg_df.csv')\n",
    "                bg_csv_ann = omero.create_annotation_file_local(\n",
    "                    connection=conn,\n",
    "                    file_path=f'{TEMP_DIR}/ch{bg_ch[0]}_bg_df.csv',\n",
    "                    description=f'Data corresponding to the background on channel {bg_ch[0]}')\n",
    "                omero.link_annotation(aip_image, bg_csv_ann)\n",
    "\n",
    "                if len(object_df) > 0:\n",
    "                    table_col_values[table_col_names.index(f'roi_intensity_{ch_names[object_ch[0]]}')].append(np.sum(aip_data[object_ch[0]]).item())\n",
    "                    table_col_values[table_col_names.index(f'object_count_{ch_names[object_ch[0]]}')].append(len(object_df))\n",
    "\n",
    "                    table_col_values[table_col_names.index(f'mean_area_{ch_names[object_ch[0]]}')].append(object_df['area'].mean().item())\n",
    "                    table_col_values[table_col_names.index(f'median_area_{ch_names[object_ch[0]]}')].append(object_df['area'].median().item())\n",
    "                    table_col_values[table_col_names.index(f'sum_area_{ch_names[object_ch[0]]}')].append(object_df['area'].sum().item())\n",
    "                    table_col_values[table_col_names.index(f'sum_intensity_{ch_names[object_ch[0]]}')].append(object_df['integrated_intensity'].sum().item())\n",
    "                    table_col_values[table_col_names.index(f'mean_intensity_{ch_names[object_ch[0]]}')].append(object_df['integrated_intensity'].sum().item() /\n",
    "                                                                                                               object_df['area'].sum().item())\n",
    "                    table_col_values[table_col_names.index(f'sum_area_bg_{ch_names[object_ch[0]]}')].append(bg_df['area'].sum().item())\n",
    "                    table_col_values[table_col_names.index(f'sum_intensity_bg_{ch_names[object_ch[0]]}')].append(bg_df['integrated_intensity'].sum().item())\n",
    "                    table_col_values[table_col_names.index(f'mean_intensity_bg_{ch_names[object_ch[0]]}')].append(bg_df['integrated_intensity'].sum().item() /\n",
    "                                                                                                                  bg_df['area'].sum().item())\n",
    "                else:\n",
    "                    logger.warning(f'No objects were detected for image {image_root_name}')\n",
    "\n",
    "                    table_col_values[table_col_names.index(f'roi_intensity_{ch_names[object_ch[0]]}')].append(0)\n",
    "                    table_col_values[table_col_names.index(f'object_count_{ch_names[object_ch[0]]}')].append(0)\n",
    "\n",
    "                    table_col_values[table_col_names.index(f'mean_area_{ch_names[object_ch[0]]}')].append(0)\n",
    "                    table_col_values[table_col_names.index(f'median_area_{ch_names[object_ch[0]]}')].append(0)\n",
    "                    table_col_values[table_col_names.index(f'sum_area_{ch_names[object_ch[0]]}')].append(0)\n",
    "                    table_col_values[table_col_names.index(f'sum_intensity_{ch_names[object_ch[0]]}')].append(0)\n",
    "                    table_col_values[table_col_names.index(f'mean_intensity_{ch_names[object_ch[0]]}')].append(0)\n",
    "                    table_col_values[table_col_names.index(f'sum_area_bg_{ch_names[object_ch[0]]}')].append(0)\n",
    "                    table_col_values[table_col_names.index(f'sum_intensity_bg_{ch_names[object_ch[0]]}')].append(0)\n",
    "                    table_col_values[table_col_names.index(f'mean_intensity_bg_{ch_names[object_ch[0]]}')].append(0)\n",
    "\n",
    "            logger.info(f'Processed image {counter}')\n",
    "\n",
    "        table = omero.create_annotation_table(connection=conn,\n",
    "                                              table_name='Aggregated_measurements',\n",
    "                                              column_names=table_col_names,\n",
    "                                              column_descriptions=table_col_names,\n",
    "                                              values=table_col_values,\n",
    "                                              )\n",
    "        omero.link_annotation(dataset, table)\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "        logger.info('Done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}